# @package _global_
defaults:
  - benchmark: category_theory_test
  - eval_settings: codet5_beam_32
  - env_settings: bm25_retrieval
  - override hydra/job_logging: 'disabled'

log_dir: <root>/data/CompCert/proof_logs/coq/base
eval_settings:
  model_name: <root>/models/ProofWala-codet5-base-coq-cat-theory-2048/checkpoint-2060
  checkpoint_dir: .log/checkpoints/ProofWala-codet5-base-coq-cat-theory-2048/checkpoint-2060
  proof_dump_dir: <root>/data/CompCert/proof_dumps/coq/wt-ct
  proof_retries: 10
  timeout_in_secs: 620
  do_lemmas_discovery: False
# eval_settings:-
#  use_hammer: AUTO
#  timeout_in_secs: 200
#  proof_retries: 10
#  temperature: 0.7

# prompt_settings:
#   # Informal proof human written
#   informal_proof_repo: data/test/informal_lean_proj
#   # Informal proof gpt35
#   informal_proof_file: .log/proofs/eval_driver/informal_few_shot/miniF2F_test/20231204-233231/informal_proofs

# To run this experiment, execute the following command:

# Few shot Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_lean  &

# Dfs Agent Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_dfs env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_lean  &

# Few shot Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_1  &

# Dfs Agent Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_dfs_always_retrieve env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_1  &

# Few shot Isabelle
# nohup python src/main/eval_benchmark.py prompt_settings=isabelle_few_shot_hammer env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_isabelle  &

# Dfs Agent Isabelle
# nohup python src/main/eval_benchmark.py prompt_settings=isabelle_dfs_hammer env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_isabelle  &