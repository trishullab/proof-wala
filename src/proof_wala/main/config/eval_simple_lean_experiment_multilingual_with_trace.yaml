# @package _global_
defaults:
  - benchmark: simple_lean_test
  - eval_settings: codet5_beam_64
  - env_settings: bm25_retrieval
  - override hydra/job_logging: 'disabled'

log_dir: <root>/data/LeanDojo_Random/proof_logs/multilingual
eval_settings:
  proof_dump_dir: <root>/data/LeanDojo_Random/proof_dumps/multilingual/wt-ct
  model_name: <root>/models/ProofWala-codet5-base-multilingual-random-2048/wt-ct/checkpoint-340000
  checkpoint_dir: .log/checkpoints/ProofWala-codet5-base-multilingual-random-2048/wt-ct/checkpoint-340000
  proof_retries: 20
  timeout_in_secs: 620
  temperature: 1.2
  # proof_tracer:
  #   folder: <root>/data/LeanDojo_Random/proof_traces/multilingual/wt-ct
benchmark:
  timeout_per_theorem_in_secs: 620
  # width: 32
  # proof_retries: 10
  # search_params:
  #   beam_width: 32
# eval_settings:
#  use_hammer: AUTO
#  timeout_in_secs: 200
#  proof_retries: 10
#  temperature: 0.7

# prompt_settings:
#   # Informal proof human written
#   informal_proof_repo: data/test/informal_lean_proj
#   # Informal proof gpt35
#   informal_proof_file: .log/proofs/eval_driver/informal_few_shot/miniF2F_test/20231204-233231/informal_proofs

# To run this experiment, execute the following command:

# Few shot Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_lean  &

# Dfs Agent Lean
# nohup python src/main/eval_benchmark.py prompt_settings=lean_dfs env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_lean  &

# Few shot Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_few_shot env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_1  &

# Dfs Agent Coq
# nohup python src/main/eval_benchmark.py prompt_settings=coq_dfs_always_retrieve env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_1  &

# Few shot Isabelle
# nohup python src/main/eval_benchmark.py prompt_settings=isabelle_few_shot_hammer env_settings=bm25_retrieval eval_settings=n_4_few_gpt35 benchmark=simple_benchmark_isabelle  &

# Dfs Agent Isabelle
# nohup python src/main/eval_benchmark.py prompt_settings=isabelle_dfs_hammer env_settings=bm25_retrieval eval_settings=n_60_dfs_gpt35_always_retrieve_no_ex benchmark=simple_benchmark_isabelle  &