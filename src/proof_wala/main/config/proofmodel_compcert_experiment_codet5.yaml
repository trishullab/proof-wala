defaults:
  - model_settings: codet5_small_2048.yaml # Name of model settings file
  - training_data_settings: proofmodel_delta_state_compcert_benchmark_training.yaml # Name of training data settings file
  - training_settings: basic_100_005 # Name of training settings file
  - override hydra/job_logging: 'disabled'

name: thrall-codet5-proofmodel-compcert-2048 # Can be any name will be used in logs
experiment_type: 'Training' # Can be 'Training' or 'Inferencing'

training_settings:
  eval_percentage: 0.002
  training_args:
    eval_steps: 500
    num_train_epochs: 5
    seed: 8341
    data_seed: 8341
    per_device_eval_batch_size: 1

# Run experiments using the following command:
# nohup torchrun --nproc-per-node 2 src/proof_wala/main/run.py &
# nohup torchrun --nproc-per-node 2 --master-port 31052  src/proof_wala/main/run.py &
# nohup torchrun --nproc-per-node 2 --master-port 31052  src/proof_wala/main/run.py --config-name test_chat_experiment.yaml &
# The default master port is 29500, but you can change it to any other port number when running multiple experiments on the same machine
# nohup torchrun --nproc-per-node 2 src/proof_wala/main/run.py model_settings=codet5_small_128 training_data_settings=simple_benchmark_training training_settings=basic_split_09_01 &
# nohup torchrun --nproc-per-node 2 src/proof_wala/main/run.py model_settings=codet5_small_128 training_data_settings=simple_benchmark_training_chat_codet5 training_settings=basic_split_09_01 &
