defaults:
  - model_settings: llama2_7b_quantized_chat_4096.yaml # Name of model settings file
  - training_data_settings: compcert_benchmark_training_chat.yaml # Name of training data settings file
  - training_settings: basic_quantized_llama2_100_0005 # Name of training settings file
  - override hydra/job_logging: 'disabled'

name: thrall-Llama-2-7b-hf-chat-lora-compcert-4096-009-001 # Can be any name will be used in logs
experiment_type: 'Training' # Can be 'Training' or 'Inferencing'

# Run experiments using the following command:
# nohup torchrun --nproc-per-node 2 src/thrall_lib/main/run.py &
# nohup torchrun --nproc-per-node 2 --master-port 31052  src/thrall_lib/main/run.py &
# The default master port is 29500, but you can change it to any other port number when running multiple experiments on the same machine
# nohup torchrun --nproc-per-node 2 src/thrall_lib/main/run.py model_settings=codet5_small_128 training_data_settings=simple_benchmark_training training_settings=basic_split_09_01 &
