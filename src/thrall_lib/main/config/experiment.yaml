defaults:
  # - model_settings: llama2_7b_quantized_1024 # Name of model settings file
  # - training_data_settings: simple_benchmark_training # Name of training data settings file
  # - training_settings: basic_quantized_llama2_split_09_01 # Name of training settings file
  # - training_settings: basic_split_09_01 # Name of training settings file
  - model_settings: codet5_small_2048 # Name of model settings file
  - training_data_settings: simple_benchmark_training # Name of training data settings file
  - training_settings: basic_split_09_01 # Name of training settings file
  - override hydra/job_logging: 'disabled'

# name: thrall-Llama-2-7b-hf-simple-1024-001-001 # Can be any name will be used in logs
name: thrall-t5-small-2048-category-test # Can be any name will be used in logs
experiment_type: 'Training' # Can be 'Training' or 'Inferencing'
training_data_settings:
  training_data_dir: <user>/data/proofsteps/category-theory/20240510-050006/test/
training_settings:
  per_device_eval_batch_size: 1
  per_device_train_batch_size: 1
  eval_steps: 50
  num_train_epochs: 100
# name: thrall-codet5-small-simple-128-001-001

# Run experiments using the following command:
# nohup torchrun --nproc-per-node 2 --master-port 31052 src/thrall_lib/main/run.py &
# nohup torchrun --nproc-per-node 2 src/thrall_lib/main/run.py model_settings=codet5_small_128 training_data_settings=simple_benchmark_training training_settings=basic_split_09_01 &
